{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Card CGAN",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyZ_ynkLOExP"
      },
      "source": [
        "Downloading and unzipping card folder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7IcHcpAU-pd"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1AyGHVflbIjzinkKBURHNVDx1wWg9JixB\n",
        "!unzip cards.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNtV_0jTOXTN"
      },
      "source": [
        "Resizing and rewriting images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvRY7EQhWrsO"
      },
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "card1 = cv2.resize(cv2.imread(\"cards/card1.JPG\", cv2.IMREAD_GRAYSCALE), (48, 48))\n",
        "card2 = cv2.resize(cv2.imread(\"cards/card2.JPG\", cv2.IMREAD_GRAYSCALE), (48, 48))\n",
        "card3 = cv2.resize(cv2.imread(\"cards/card3.JPG\", cv2.IMREAD_GRAYSCALE), (48, 48))\n",
        "card4 = cv2.resize(cv2.imread(\"cards/card4.JPG\", cv2.IMREAD_GRAYSCALE), (48, 48))\n",
        "cv2.imwrite('/content/Card_1.jpg', card1)\n",
        "cv2.imwrite('/content/Card_2.jpg', card2)\n",
        "cv2.imwrite('/content/Card_3.jpg', card3)\n",
        "cv2.imwrite('/content/Card_4.jpg', card4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7t9eX0SOhLe"
      },
      "source": [
        "Data augmentation (flipping and shift), making the training array set and labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqs5gyGRaIcC"
      },
      "source": [
        "from PIL import Image\n",
        "card1 = Image.open('/content/Card_1.jpg')\n",
        "card2 = Image.open('/content/Card_2.jpg')\n",
        "card3 = Image.open('/content/Card_3.jpg')\n",
        "card4 = Image.open('/content/Card_4.jpg')\n",
        "def leftshift(image, n):\n",
        "  image = np.array(image)\n",
        "  for i in range(image.shape[0]):\n",
        "    for j in range(image.shape[1]):\n",
        "      if (i < image.shape[1] - n):\n",
        "        image[j][i] = image[j][i + n]\n",
        "  return image\n",
        "def rightshift(image, n):\n",
        "  image = np.array(image)\n",
        "  for i in range(image.shape[0], 1, -1):\n",
        "    for j in range(image.shape[1]):\n",
        "      if (i < image.shape[0] - n):\n",
        "        image[j][i] = image[j][i - n]\n",
        "  return image\n",
        "def upshift(image, n):\n",
        "  image = np.array(image)\n",
        "  for j in range(image.shape[0]):\n",
        "    for i in range(image.shape[1]):\n",
        "      if (j < image.shape[0] - n and j > n):\n",
        "        image[j][i] = image[j + n][i]\n",
        "  return image\n",
        "def downshift(image, n):\n",
        "  image = np.array(image)\n",
        "  for j in range(image.shape[0], 1, -1):\n",
        "    for i in range(image.shape[1]):\n",
        "      if (j > n and j < image.shape[0] - n):\n",
        "        image[j][i] = image[j - n][i]\n",
        "  return image\n",
        "plt.imshow(downshift(card1, 6))\n",
        "def transform_preprocess(image):\n",
        "  final_images = []\n",
        "  horzflip = image.transpose(method = Image.FLIP_LEFT_RIGHT)\n",
        "  vertflip = image.transpose(method = Image.FLIP_TOP_BOTTOM)\n",
        "  reflflip = horzflip.transpose(method = Image.FLIP_TOP_BOTTOM)\n",
        "  images = [image, horzflip, vertflip, reflflip]\n",
        "  for image in [image, horzflip]:\n",
        "    images.append(image.rotate(90))\n",
        "    images.append(image.rotate(270))\n",
        "  for image in images:\n",
        "    for m in range(9):\n",
        "      final_images.append(leftshift(image, m))\n",
        "      for l in range(6):\n",
        "        final_images.append(upshift(leftshift(image, m), l))\n",
        "        final_images.append(downshift(leftshift(image, m), l))\n",
        "    for m in range(6):\n",
        "      final_images.append(rightshift(image, m))\n",
        "      for l in range(6):\n",
        "        final_images.append(upshift(rightshift(image, m), l))\n",
        "        final_images.append(downshift(rightshift(image, m), l))\n",
        "    final_images.append(np.array(image))\n",
        "  final_images = np.array(final_images)\n",
        "  return final_images\n",
        "index_array = []\n",
        "Card1 = transform_preprocess(card1)\n",
        "for i in range(Card1.shape[0]):\n",
        "  index_array.append(0)\n",
        "Card2 = transform_preprocess(card2)\n",
        "for i in range(Card2.shape[0]):\n",
        "  index_array.append(1)\n",
        "Card3 = transform_preprocess(card3)\n",
        "for i in range(Card3.shape[0]):\n",
        "  index_array.append(2)\n",
        "Card4 = transform_preprocess(card4)\n",
        "for i in range(Card4.shape[0]):\n",
        "  index_array.append(3)\n",
        "index_array = np.array(index_array)\n",
        "FinalCards = np.concatenate((Card1, Card2, Card3, Card4), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTO5E0nBOyEi"
      },
      "source": [
        "Building, training, and saving the cGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y78sXalM17Q"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import argparse\n",
        "import pdb\n",
        "from keras.layers import Activation, Dense, Input\n",
        "from keras.layers import Conv2D, Flatten\n",
        "from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import concatenate\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "\n",
        "def build_generator(inputs, labels, image_size):\n",
        "    image_resize = (image_size[0] // 4, image_size[1] // 4)\n",
        "    kernel_size = 5\n",
        "    layer_filters = [128, 64, 32, 1]\n",
        "    x = concatenate([inputs, labels], axis=1)\n",
        "    x = Dense(image_resize[0] * image_resize[1] * layer_filters[0])(x)\n",
        "    x = Reshape((image_resize[0], image_resize[1], layer_filters[0]))(x)\n",
        "    for filters in layer_filters:\n",
        "        if filters > layer_filters[-2]:\n",
        "            strides = 2\n",
        "        else:\n",
        "            strides = 1\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = Reshape((48, 48, 1))(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    generator = Model([inputs, labels], x, name='generator')\n",
        "    return generator\n",
        "\n",
        "def build_discriminator(inputs, labels, image_size):\n",
        "    kernel_size = 5\n",
        "    layer_filters = [32, 64, 128, 256]\n",
        "    x = inputs\n",
        "    y = Dense(image_size[0] * image_size[1])(labels)\n",
        "    y = Reshape((image_size[0], image_size[1], 1))(y)\n",
        "    x = concatenate([x, y])\n",
        "    for filters in layer_filters:\n",
        "        if filters == layer_filters[-1]:\n",
        "            strides = 1\n",
        "        else:\n",
        "            strides = 2\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = 'same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1)(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    discriminator = Model([inputs, labels], x, name='discriminator')\n",
        "    return discriminator\n",
        "\n",
        "def train(models, data, params):\n",
        "    losss = []\n",
        "    accc = []\n",
        "    generator, discriminator, adversarial = models\n",
        "    x_train, y_train = data\n",
        "    batch_size, latent_size, train_steps, num_labels, model_name = params\n",
        "    save_interval = 500\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[64, latent_size])\n",
        "    noise_class = np.eye(num_labels)[np.arange(0, 64) % num_labels]\n",
        "    print (noise_class)\n",
        "    train_size = x_train.shape[0]\n",
        "    print(model_name, \"Labels for generated images: \", np.argmax(noise_class, axis=1))\n",
        "    accavg = 0\n",
        "    accavg1 = 0\n",
        "    epochs = [i for i in range(train_steps)]\n",
        "    for i in range(train_steps):\n",
        "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
        "        real_images = x_train[rand_indexes]\n",
        "        real_labels = y_train[rand_indexes]\n",
        "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels, batch_size)]\n",
        "        fake_images = generator.predict([noise, fake_labels])\n",
        "        x = np.concatenate((real_images, fake_images))\n",
        "        labels = np.concatenate((real_labels, fake_labels))\n",
        "        y = np.ones([2 * batch_size, 1])\n",
        "        y[batch_size:, :] = 0.0\n",
        "        loss, acc = discriminator.train_on_batch([x, labels], y)\n",
        "        losss.append(loss)\n",
        "        accc.append(acc)\n",
        "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
        "        accavg += acc\n",
        "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels, batch_size)]\n",
        "        y = np.ones([batch_size, 1])\n",
        "        loss, acc = adversarial.train_on_batch([noise, fake_labels], y)\n",
        "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
        "        accavg1 += acc\n",
        "        print(log)\n",
        "        if (i + 1) % save_interval == 0:\n",
        "            accavg = accavg / save_interval\n",
        "            accavg1 = accavg1 / save_interval\n",
        "            print (\"Average discriminator accuracy: \" + str(accavg))\n",
        "            print (\"Average adversarial accuracy: \" + str(accavg1))\n",
        "            accavg = 0\n",
        "            accavg1 = 0\n",
        "            plot_images(generator, noise_input, noise_class, show = True, step = i + 1)\n",
        "    plt.plot(epochs, losss)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Discriminator Loss')\n",
        "    plt.show()\n",
        "    plt.plot(epochs, accc)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Discriminator Accuracy\")\n",
        "    plt.show()\n",
        "    generator.save(model_name + \".h5\")\n",
        "\n",
        "def plot_images(generator, noise_input, noise_class, show=False, step=0, model_name=\"gan\"):\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    images = generator.predict([noise_input, noise_class])\n",
        "    print(model_name , \" labels for generated images: \", np.argmax(noise_class, axis=1))\n",
        "    plt.figure(figsize=(11.1, 11.1))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        plt.imshow(np.array(images[i - 1]).reshape((48, 48)))\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')\n",
        "\n",
        "def build_and_train_models():\n",
        "    x_train = FinalCards\n",
        "    y_train = index_array\n",
        "    y_train = to_categorical(y_train)\n",
        "    x_train = np.reshape(x_train, [x_train.shape[0], x_train.shape[1], x_train.shape[2], 1])\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    model_name = \"cgan_card\"\n",
        "    latent_size = 2\n",
        "    batch_size = 64\n",
        "    train_steps = 40000\n",
        "    lr = 1e-4\n",
        "    decay = 6e-8\n",
        "    input_shape = (48, 48, 1)\n",
        "    label_shape = (4,)\n",
        "    image_size = (48, 48)\n",
        "    inputs = Input(shape=input_shape, name='discriminator_input')\n",
        "    labels = Input(shape=label_shape, name='class_labels')\n",
        "    discriminator = build_discriminator(inputs, labels, image_size)\n",
        "    optimizer = RMSprop(lr=lr, decay=decay)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    discriminator.summary()\n",
        "    input_shape = (latent_size, )\n",
        "    inputs = Input(shape=input_shape, name='z_input')\n",
        "    generator = build_generator(inputs, labels, image_size)\n",
        "    generator.summary()\n",
        "    optimizer = RMSprop(lr=lr*0.75, decay=decay*0.75)\n",
        "    discriminator.trainable = False\n",
        "    outputs = discriminator([generator([inputs, labels]), labels])\n",
        "    adversarial = Model([inputs, labels], outputs, name=model_name)\n",
        "    adversarial.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    adversarial.summary()\n",
        "    models = (generator, discriminator, adversarial)\n",
        "    data = (x_train, y_train)\n",
        "    num_labels = 4\n",
        "    params = (batch_size, latent_size, train_steps, num_labels, model_name)\n",
        "    train(models, data, params)\n",
        "    \n",
        "def test_generator(generator, class_label=None):\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "    step = 0\n",
        "    if class_label is None:\n",
        "        num_labels = 10\n",
        "        noise_class = np.eye(num_labels)[np.random.choice(num_labels, 16)]\n",
        "    else:\n",
        "        noise_class = np.zeros((16, 10))\n",
        "        noise_class[:,class_label] = 1\n",
        "        step = class_label\n",
        "    plot_images(generator, noise_input=noise_input, noise_class=noise_class, show=True, step=step, model_name=\"test_outputs\")\n",
        "build_and_train_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgPjzH2UPNiD"
      },
      "source": [
        "Making the training gif:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqd2YCcGLdtE"
      },
      "source": [
        "datadir = '/content/gan'\n",
        "filelist = sorted(os.listdir(datadir))\n",
        "frames = []\n",
        "for fil in filelist:\n",
        "  path = '/content/gan/' + fil\n",
        "  fil = Image.open(path)\n",
        "  frames.append(fil)\n",
        "frames[0].save('Card_Training.gif', format='GIF', append_images=frames[1:], save_all=True, duration = 300, loop = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ1Kt1j1PQgk"
      },
      "source": [
        "Making the images for the card predictions based on the two latent-space variables: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nCf4I8TL5Ze"
      },
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "generator = load_model('/content/cgan_card.h5')\n",
        "labels = np.array(((1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1)))\n",
        "images = []\n",
        "latent_vals = []\n",
        "for i in range(20):\n",
        "  for j in range(20):\n",
        "    latent_val = np.array((i/20, j/20))\n",
        "    latent_vals.append(latent_val)\n",
        "latent_vals = np.array(latent_vals)\n",
        "predictions = []\n",
        "for label in labels:\n",
        "  classes = [label] * 400\n",
        "  classes = np.array(classes)\n",
        "  images = generator.predict([latent_vals, classes])\n",
        "  predictions.append(images)\n",
        "predictions = np.array(predictions)\n",
        "predictions = predictions.reshape((4, 20, 20, 48, 48))\n",
        "for x in predictions:\n",
        "  l = 0\n",
        "  images = []\n",
        "  for y in x:\n",
        "    k = 0\n",
        "    for z in y:\n",
        "      if k == 0:\n",
        "        axis_img = z\n",
        "      else:\n",
        "        axis_img = np.concatenate((axis_img, z))\n",
        "      k += 1\n",
        "    images.append(axis_img)\n",
        "  images = np.array((images))\n",
        "  grid = []\n",
        "  for img in images:\n",
        "    if l == 0:\n",
        "      grid = img\n",
        "    else:\n",
        "      grid = np.concatenate((grid, img), axis = 1)\n",
        "    l += 1\n",
        "  plt.imshow(grid)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}