{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CardDCGAN",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfupFGcEsC-m"
      },
      "source": [
        "Downloading the dataset of four cards:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhpVNQFsd1k0"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1AyGHVflbIjzinkKBURHNVDx1wWg9JixB\n",
        "!unzip cards.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2s-x0-8sOCt"
      },
      "source": [
        "Resizing the images and saving those images to the runtime:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4r3WKMAd9Bp"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "card1 = cv2.resize(cv2.imread(\"cards/card1.JPG\", cv2.IMREAD_GRAYSCALE), (48, 48))\n",
        "card2 = cv2.resize(cv2.imread(\"cards/card2.JPG\", cv2.IMREAD_GRAYSCALE), (48, 48))\n",
        "card3 = cv2.resize(cv2.imread(\"cards/card3.JPG\", cv2.IMREAD_GRAYSCALE), (48, 48))\n",
        "card4 = cv2.resize(cv2.imread(\"cards/card4.JPG\", cv2.IMREAD_GRAYSCALE), (48, 48))\n",
        "plt.imshow(card1)\n",
        "plt.show()\n",
        "plt.imshow(card2)\n",
        "plt.show()\n",
        "plt.imshow(card3)\n",
        "plt.show()\n",
        "plt.imshow(card4)\n",
        "plt.show()\n",
        "cv2.imwrite('/content/Card_1.jpg', card1)\n",
        "cv2.imwrite('/content/Card_2.jpg', card2)\n",
        "cv2.imwrite('/content/Card_3.jpg', card3)\n",
        "cv2.imwrite('/content/Card_4.jpg', card4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjBB8t7XtQLF"
      },
      "source": [
        "Data augmentation of the images, flipping and shifting (no shearing) and storing all of those images in a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWrWgSLJeAfz"
      },
      "source": [
        "from PIL import Image\n",
        "card1 = Image.open('/content/Card_1.jpg')\n",
        "card2 = Image.open('/content/Card_2.jpg')\n",
        "card3 = Image.open('/content/Card_3.jpg')\n",
        "card4 = Image.open('/content/Card_4.jpg')\n",
        "def leftshift(image, n):\n",
        "  image = np.array(image)\n",
        "  for i in range(image.shape[0]):\n",
        "    for j in range(image.shape[1]):\n",
        "      if (i < image.shape[1] - n):\n",
        "        image[j][i] = image[j][i + n]\n",
        "  return image\n",
        "def rightshift(image, n):\n",
        "  image = np.array(image)\n",
        "  for i in range(image.shape[0], 1, -1):\n",
        "    for j in range(image.shape[1]):\n",
        "      if (i < image.shape[0] - n):\n",
        "        image[j][i] = image[j][i - n]\n",
        "  return image\n",
        "def upshift(image, n):\n",
        "  image = np.array(image)\n",
        "  for j in range(image.shape[0]):\n",
        "    for i in range(image.shape[1]):\n",
        "      if (j < image.shape[0] - n and j > n):\n",
        "        image[j][i] = image[j + n][i]\n",
        "  return image\n",
        "def downshift(image, n):\n",
        "  image = np.array(image)\n",
        "  for j in range(image.shape[0], 1, -1):\n",
        "    for i in range(image.shape[1]):\n",
        "      if (j > n and j < image.shape[0] - n):\n",
        "        image[j][i] = image[j - n][i]\n",
        "  return image\n",
        "plt.imshow(downshift(card1, 6))\n",
        "def transform_preprocess(image):\n",
        "  final_images = []\n",
        "  horzflip = image.transpose(method = Image.FLIP_LEFT_RIGHT)\n",
        "  vertflip = image.transpose(method = Image.FLIP_TOP_BOTTOM)\n",
        "  reflflip = horzflip.transpose(method = Image.FLIP_TOP_BOTTOM)\n",
        "  images = [image, horzflip, vertflip, reflflip]\n",
        "  for image in [image, horzflip]:\n",
        "    images.append(image.rotate(90))\n",
        "    images.append(image.rotate(270))\n",
        "  for image in images:\n",
        "    for m in range(9):\n",
        "      final_images.append(leftshift(image, m))\n",
        "      for l in range(6):\n",
        "        final_images.append(upshift(leftshift(image, m), l))\n",
        "        final_images.append(downshift(leftshift(image, m), l))\n",
        "    for m in range(6):\n",
        "      final_images.append(rightshift(image, m))\n",
        "      for l in range(6):\n",
        "        final_images.append(upshift(rightshift(image, m), l))\n",
        "        final_images.append(downshift(rightshift(image, m), l))\n",
        "    final_images.append(np.array(image))\n",
        "  final_images = np.array(final_images)\n",
        "  return final_images\n",
        "index_array1 = []\n",
        "index_array2 = []\n",
        "index_array3 = []\n",
        "index_array4 = []\n",
        "Card1 = transform_preprocess(card1)\n",
        "for i in range(Card1.shape[0]):\n",
        "  index_array1.append(0)\n",
        "Card2 = transform_preprocess(card2)\n",
        "for i in range(Card2.shape[0]):\n",
        "  index_array2.append(0)\n",
        "Card3 = transform_preprocess(card3)\n",
        "for i in range(Card3.shape[0]):\n",
        "  index_array3.append(0)\n",
        "Card4 = transform_preprocess(card4)\n",
        "for i in range(Card4.shape[0]):\n",
        "  index_array4.append(0)\n",
        "FinalCards = np.concatenate((Card1, Card2, Card3, Card4), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX-SqP9bx73k"
      },
      "source": [
        "Building, training, and saving the card classifier for classification in finding out latent spaces' influence on class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbfN2NLQx7Qf"
      },
      "source": [
        "import numpy as np #Importing needed libraries\n",
        "from tensorflow import random\n",
        "from keras import losses\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.preprocessing import image\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain_set1, Xtest_set1, ytrain1, ytest1 = train_test_split(Card1, index_array1, test_size = 0.25)\n",
        "Xtrain_set2, Xtest_set2, ytrain2, ytest2 = train_test_split(Card2, index_array2, test_size = 0.25)\n",
        "Xtrain_set3, Xtest_set3, ytrain3, ytest3 = train_test_split(Card3, index_array3, test_size = 0.25)\n",
        "Xtrain_set4, Xtest_set4, ytrain4, ytest4 = train_test_split(Card4, index_array4, test_size = 0.25)\n",
        "X_train = np.concatenate((Xtrain_set1, Xtrain_set2, Xtrain_set3, Xtrain_set4)) \n",
        "X_test = np.concatenate((Xtest_set1, Xtest_set2, Xtest_set3, Xtest_set4))\n",
        "y_train = np.concatenate((ytrain1, ytrain2, ytrain3, ytrain4))\n",
        "y_test = np.concatenate((ytest1, ytest2, ytest3, ytest4))\n",
        "model = Sequential([Flatten(input_shape=(48, 48)), Dense(128, activation='relu'), Dense(4)])\n",
        "model.compile(optimizer='adam', loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 40)\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "model.save('Card_Classifier.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdGcKQTeuzzC"
      },
      "source": [
        "Building, training, and saving the dcGAN and its training frames:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFmHw6DyeIht"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "import os\n",
        "from keras.layers import Activation, Dense, Input\n",
        "from keras.layers import Conv2D, Flatten\n",
        "from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import concatenate\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "def build_generator(inputs, image_size):\n",
        "    image_resize = (image_size[0] // 4, image_size[1] // 4)\n",
        "    kernel_size = 5\n",
        "    layer_filters = [128, 64, 32, 1]\n",
        "    x = inputs\n",
        "    x = Dense(image_resize[0] * image_resize[1] * layer_filters[0])(x)\n",
        "    x = Reshape((image_resize[0], image_resize[1], layer_filters[0]))(x)\n",
        "    for filters in layer_filters:\n",
        "        if filters > layer_filters[-2]:\n",
        "            strides = 2\n",
        "        else:\n",
        "            strides = 1\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = Reshape((48, 48, 1))(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    generator = Model(inputs, x, name='generator')\n",
        "    return generator\n",
        "def build_discriminator(inputs, image_size):\n",
        "    kernel_size = 5\n",
        "    layer_filters = [32, 64, 128, 256]\n",
        "    x = inputs\n",
        "    for filters in layer_filters:\n",
        "        if filters == layer_filters[-1]:\n",
        "            strides = 1\n",
        "        else:\n",
        "            strides = 2\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = 'same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1)(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    discriminator = Model(inputs, x, name='discriminator')\n",
        "    return discriminator\n",
        "def train(models, data, params):\n",
        "    losss = []\n",
        "    accc = []\n",
        "    generator, discriminator, adversarial = models\n",
        "    x_train = data\n",
        "    batch_size, latent_size, train_steps, model_name = params\n",
        "    save_interval = 500\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[64, latent_size])\n",
        "    train_size = x_train.shape[0]\n",
        "    accavg = 0\n",
        "    accavg1 = 0\n",
        "    epochs = [i for i in range(train_steps)]\n",
        "    frames = []\n",
        "    for i in range(train_steps):\n",
        "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
        "        real_images = x_train[rand_indexes]\n",
        "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "        fake_images = generator.predict(noise)\n",
        "        x = np.concatenate((real_images, fake_images))\n",
        "        y = np.ones([2 * batch_size, 1])\n",
        "        y[batch_size:, :] = 0.0\n",
        "        loss, acc = discriminator.train_on_batch(x, y)\n",
        "        losss.append(loss)\n",
        "        accc.append(acc)\n",
        "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
        "        accavg += acc\n",
        "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "        y = np.ones([batch_size, 1])\n",
        "        loss, acc = adversarial.train_on_batch(noise, y)\n",
        "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
        "        accavg1 += acc\n",
        "        print(log)\n",
        "        if (i + 1) % save_interval == 0:\n",
        "            accavg = accavg / save_interval\n",
        "            accavg1 = accavg1 / save_interval\n",
        "            print (\"Average discriminator accuracy: \" + str(accavg))\n",
        "            print (\"Average adversarial accuracy: \" + str(accavg1))\n",
        "            accavg = 0\n",
        "            accavg1 = 0\n",
        "            plot_images(generator, noise_input, show = True, step = i + 1)\n",
        "            images = generator.predict(noise_input)\n",
        "            frames.append(np.array(images[0]).reshape((48, 48)))\n",
        "    plt.plot(epochs, losss)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Discriminator Loss')\n",
        "    plt.show()\n",
        "    plt.plot(epochs, accc)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Discriminator Accuracy\")\n",
        "    plt.show()\n",
        "    generator.save(model_name + \".h5\")\n",
        "def plot_images(generator, noise_input, show=False, step=0, model_name=\"gan\"):\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    images = generator.predict(noise_input)\n",
        "    plt.figure(figsize=(11.1, 11.1))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        plt.imshow(np.array(images[i - 1]).reshape((48, 48)))\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')\n",
        "def build_and_train_models():\n",
        "    x_train = FinalCards\n",
        "    x_train = np.reshape(x_train, [x_train.shape[0], x_train.shape[1], x_train.shape[2], 1])\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    model_name = \"dcgan_card\"\n",
        "    latent_size = 2\n",
        "    batch_size = 64\n",
        "    train_steps = 40000\n",
        "    lr = 1e-4\n",
        "    decay = 6e-8\n",
        "    input_shape = (48, 48, 1)\n",
        "    label_shape = (4,)\n",
        "    image_size = (48, 48)\n",
        "    inputs = Input(shape=input_shape, name='discriminator_input')\n",
        "    labels = Input(shape=label_shape, name='class_labels')\n",
        "    discriminator = build_discriminator(inputs, image_size)\n",
        "    optimizer = RMSprop(lr=lr, decay=decay)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    discriminator.summary()\n",
        "    input_shape = (latent_size, )\n",
        "    inputs = Input(shape=input_shape, name='z_input')\n",
        "    generator = build_generator(inputs, image_size)\n",
        "    generator.summary()\n",
        "    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "    discriminator.trainable = False\n",
        "    outputs = discriminator(generator(inputs))\n",
        "    adversarial = Model(inputs, outputs, name=model_name)\n",
        "    adversarial.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    adversarial.summary()\n",
        "    models = (generator, discriminator, adversarial)\n",
        "    data = x_train\n",
        "    params = (batch_size, latent_size, train_steps, model_name)\n",
        "    train(models, data, params)\n",
        "def test_generator(generator, class_label=None):\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "    step = 0\n",
        "    if class_label is None:\n",
        "        num_labels = 10\n",
        "        noise_class = np.eye(num_labels)[np.random.choice(num_labels, 16)]\n",
        "    else:\n",
        "        noise_class = np.zeros((16, 10))\n",
        "        noise_class[:,class_label] = 1\n",
        "        step = class_label\n",
        "    plot_images(generator, noise_input=noise_input, noise_class=noise_class, show=True, step=step, model_name=\"test_outputs\")\n",
        "build_and_train_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82NSnmIvu_oD"
      },
      "source": [
        "Making the gif"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmebDLtl-por"
      },
      "source": [
        "datadir = '/content/gan'\n",
        "filelist = sorted(os.listdir(datadir))\n",
        "frames = []\n",
        "for fil in filelist:\n",
        "  path = '/content/gan/' + fil\n",
        "  fil = Image.open(path)\n",
        "  frames.append(fil)\n",
        "frames[0].save('Card_Training.gif', format='GIF', append_images=frames[1:], save_all=True, duration = 300, loop = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn0EIPVMvWjM"
      },
      "source": [
        "Getting the generator to predict for certain (l1, l2) values, with the classifier predicting what classes it generated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFCQhqdLch8g"
      },
      "source": [
        "from keras.models import load_model\n",
        "import pdb\n",
        "import numpy as np\n",
        "generator = load_model('/content/dcgan_card.h5')\n",
        "classifier = load_model('/content/Card_Classifier.h5')\n",
        "latent_vals = []\n",
        "for i in range(500):\n",
        "  for j in range(500):\n",
        "    array = np.array((i/500, j/500))\n",
        "    latent_vals.append(array)\n",
        "latent_vals = np.array(latent_vals)\n",
        "images = generator.predict(latent_vals)\n",
        "classes = classifier.predict(images)\n",
        "class_list = []\n",
        "for prediction in classes:\n",
        "  prediction = list(prediction)\n",
        "  max_value = max(prediction)\n",
        "  max_index = prediction.index(max_value)  \n",
        "  class_list.append(max_index)\n",
        "k = 0\n",
        "clubslis = []\n",
        "spadeslis = []\n",
        "heartslis = []\n",
        "diamondslis = []\n",
        "for val in latent_vals:\n",
        "  if class_list[k] == 0:\n",
        "    clubslis.append(val)\n",
        "  elif class_list[k] == 1:\n",
        "    spadeslis.append(val)\n",
        "  elif class_list[k] == 2:\n",
        "    heartslis.append(val)\n",
        "  else:\n",
        "    diamondslis.append(val)\n",
        "  k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzwF5tSYv34S"
      },
      "source": [
        "Plotting which class corresponds to which latent space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqtOYQw7RtcK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "clubsx = []\n",
        "clubsy = []\n",
        "spadesx = []\n",
        "spadesy = []\n",
        "heartsx = []\n",
        "heartsy = []\n",
        "diamondsx = []\n",
        "diamondsy = []\n",
        "for x, y in clubslis:\n",
        "  clubsx.append(x)\n",
        "  clubsy.append(y)\n",
        "for x, y in spadeslis:\n",
        "  spadesx.append(x)\n",
        "  spadesy.append(y)\n",
        "for x, y in heartslis:\n",
        "  heartsx.append(x)\n",
        "  heartsy.append(y)\n",
        "for x, y in diamondslis:\n",
        "  diamondsx.append(x)\n",
        "  diamondsy.append(y)\n",
        "plt.scatter(clubsx, clubsy, label = 'clubs')\n",
        "plt.scatter(spadesx, spadesy, label = 'spades')\n",
        "plt.scatter(heartsx, heartsy, label = 'hearts')\n",
        "plt.scatter(diamondsx, diamondsy, label = 'diamond')\n",
        "plt.xlabel(\"l1\")\n",
        "plt.ylabel('l2')\n",
        "plt.title(\"Latent space values' influence on class\")\n",
        "plt.legend(loc = 'upper left')\n",
        "plt.savefig('latent_space_graph.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}